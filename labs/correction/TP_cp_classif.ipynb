{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/aangelopoulos/conformal-prediction/blob/main/notebooks/imagenet-smallest-sets.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conformal prediction for classification purpose\n",
    "Inspired by the tutorial of Angelopoulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "exec(requests.get(\"https://raw.githubusercontent.com/claireBoyer/tutorial-conformal-prediction/main/labs/aux-npt/get-send-code.html\").content)\n",
    "\n",
    "npt_config = {\n",
    "    'session_name': 'TutoCP',\n",
    "    'session_owner': 'aymeric',\n",
    "    'sender_name': input(\"Your name:\"),\n",
    "}\n",
    "send('started', 20)\n",
    "\n",
    "\n",
    "# The ''send'' function enables us to see which question you have reached\n",
    "# If this cell keeps runnning for more than a minute, restart kernel \n",
    "# If it happens again, redefine \n",
    "# def send(a,b): return()\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "!pip install -U --no-cache-dir gdown --pre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "\n",
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load cached data\n",
    "if not os.path.exists('../data'):\n",
    "    os.system('gdown 1h7S6N_Rx7gdfO3ZunzErZy6H7620EbZK -O ../data.tar.gz')\n",
    "    os.system('tar -xf ../data.tar.gz -C ../')\n",
    "    os.system('rm ../data.tar.gz')\n",
    "if not os.path.exists('../data/imagenet/human_readable_labels.json'):\n",
    "    !wget -nv -O ../data/imagenet/human_readable_labels.json -L https://raw.githubusercontent.com/anishathalye/imagenet-simple-labels/master/imagenet-simple-labels.json\n",
    "\n",
    "data = np.load('../data/imagenet/imagenet-resnet152.npz')\n",
    "example_paths = os.listdir('../data/imagenet/examples')\n",
    "smx = data['smx']\n",
    "labels = data['labels'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting parameters for conformal prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Problem setup\n",
    "n_cal = 1000 # number of calibration points\n",
    "alpha = 0.1 # 1-alpha is the desired coverage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split the softmax scores into calibration and validation sets (save the shuffling)\n",
    "idx = np.array([1] * n_cal + [0] * (smx.shape[0]-n_cal)) > 0\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(idx)\n",
    "cal_smx, test_smx = smx[idx,:], smx[~idx,:]\n",
    "cal_labels, test_labels = labels[idx], labels[~idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding what is stored in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Zoom on the labels in the calibration set\n",
    "print(\"The first 10 labels in the calibration set are \", cal_labels[:10])\n",
    "print(\"The minimal label is \",np.min(cal_labels))\n",
    "print(\"The maximal label is \",np.max(cal_labels))\n",
    "plt.hist(cal_labels,bins=1000);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Zoom on the labels in the test set\n",
    "print(\"The first 10 labels in the test set are \", test_labels[:10])\n",
    "print(\"The minimal label is \",np.min(test_labels))\n",
    "print(\"The maximal label is \",np.max(test_labels))\n",
    "plt.hist(test_labels,bins=1000);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"The total number of different labels in the dataset:\",len(np.unique(labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Look at a row of cal_smx: this corresponds to the predicted probabilities \n",
    "# (the training has been already performed)\n",
    "plt.plot(cal_smx[450])\n",
    "print(\"The sum of a row of cal_smx gives \",np.sum(cal_smx[450]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A first way for conformal prediction\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    1. For each calibration point, compute a score. <br>\n",
    "    2. And then evaluate an empirical quantile of the calibration scores.  \n",
    "</div> \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1: get conformal scores\n",
    "cal_scores = 1-cal_smx[np.arange(n_cal),cal_labels] # TODO OPERAND\n",
    "\n",
    "\n",
    "# 2: get adjusted quantile\n",
    "q_level = np.ceil((n_cal+1)*(1-alpha))/n_cal                  # TODO OPERAND\n",
    "qhat = np.quantile(cal_scores, q_level, interpolation='higher')# TODO OPERAND\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    3. Form the prediction sets for the test set\n",
    "</div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 3: form prediction sets\n",
    "prediction_sets = test_smx >= (1-qhat) # 3: form prediction sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    4. Compute the empirical coverage\n",
    "</div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate empirical coverage\n",
    "empirical_coverage = prediction_sets[np.arange(prediction_sets.shape[0]),test_labels].mean() #TODO OPERAND\n",
    "print(f\"The empirical coverage is: {empirical_coverage}\")\n",
    "send([\"The empirical coverage is:\", empirical_coverage], 21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    5. Illustrate prediction sets for some points of the test set\n",
    "</div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Making the labels human-readable\n",
    "with open('../data/imagenet/human_readable_labels.json') as f:\n",
    "    label_strings = np.array(json.load(f))\n",
    "\n",
    "# Show some examples\n",
    "example_paths =os.listdir('../data/imagenet/examples')\n",
    "for i in range(10):\n",
    "    rand_path = np.random.choice(example_paths)\n",
    "    img = imread('../data/imagenet/examples/' + rand_path )\n",
    "    img_index = int(rand_path.split('.')[0])\n",
    "    #\n",
    "    prediction_set = smx[img_index] > 1-qhat #TODO OPERAND\n",
    "    #\n",
    "    plt.figure()\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    send(plt, 22)\n",
    "    plt.show()\n",
    "    print(f\"The prediction set is: {list(label_strings[prediction_set])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">This method leads to <b>small prediction sets</b>, but sacrifices <b>adaptivity</b>. </div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Towards more adaptive prediction sets \n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    <ol>\n",
    "<li>Sort in decreasing order $\\hat{p}_{\\sigma_i(1)}(X_i) \\geq ... \\geq  \\hat{p}_{\\sigma_i(C)}(X_i)$</li>\n",
    "   \n",
    "<li> Compute the calibration scores $S_i = \\sum_{k=1}^{\\sigma_i^{-1}(Y_i)} \\hat{p}_{\\sigma_i(k)}(X_i)$ (sum of the estimated probabilities associated to classes at least as large as that of the true class $Y_i$)} </li>\n",
    "    <li> Get the quantile $q_{1-\\alpha}(\\mathcal{S})$ </li>\n",
    "<li> Return the classes $\\sigma_{\\text{new}}(1),... ,\\sigma_{\\text{new}}(r^\\star)$ where $r^{\\star} = \\text{argmax}_{1 \\leq r \\leq C}\\left\\{ \\sum_{k=1}^{r} \\hat{p}_{\\sigma_{\\text{new}}(k)}(X_{\\text{new}}) < q_{1-\\alpha}(\\mathcal{S}) \\right\\} + 1$</li>\n",
    "         </ol>\n",
    "\n",
    "NB : to avoid the +1, you can use the corrected quantile ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get scores\n",
    "\n",
    "# get for each row the position of the predicted probabilities in decreasing order\n",
    "\n",
    "cal_pi = cal_smx.argsort(1)[:,::-1] #TODO OPERAND\n",
    "#argsort in increasing order, so order reverting by [:,::-1] \n",
    "\n",
    "# form for each row the predicted probabilities in decreasing order\n",
    "cal_srt = np.take_along_axis(cal_smx,cal_pi,axis=1) #TODO OPERAND\n",
    "\n",
    "\n",
    "# get the rank of the true label in the sorted predicted probabilities\n",
    "cal_L = np.where(cal_pi == cal_labels[:,None])[1] #TODO OPERAND\n",
    "\n",
    "# compute the calibration scores (why minus something????)\n",
    "cal_scores = cal_srt.cumsum(axis=1)[np.arange(n_cal),cal_L] #TODO OPERAND\n",
    "\n",
    "# Get the score quantile\n",
    "qhat = np.quantile(cal_scores, np.ceil((n_cal+1)*(1-alpha))/n_cal, interpolation='higher') #TODO OPERAND\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Deploy on the test set\n",
    "n_test = test_smx.shape[0]\n",
    "\n",
    "\n",
    "# sorting the predicted probabilities (softmax outputs) on the test set\n",
    "test_pi = test_smx.argsort(1)[:,::-1] #TODO OPERAND\n",
    "\n",
    "\n",
    "# reordering\n",
    "test_srt = np.take_along_axis(test_smx,test_pi,axis=1) #TODO OPERAND\n",
    "\n",
    "\n",
    "#test_srt_cumsum = test_srt.cumsum(axis=1)\n",
    "# cumulative softmax outputs\n",
    "indicators = test_srt.cumsum(axis=1) <= qhat #TODO OPERAND\n",
    "prediction_sets = np.take_along_axis(indicators,test_pi.argsort(axis=1),axis=1) #TODO OPERAND\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate empirical coverage\n",
    "\n",
    "empirical_coverage = prediction_sets[np.arange(n_test),test_labels].mean() #TODO OPERAND\n",
    "print(f\"The empirical coverage is: {empirical_coverage}\")\n",
    "print(f\"The quantile is: {qhat}\")\n",
    "send([\"The empirical coverage is:\", empirical_coverage], 23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show some examples\n",
    "with open('../data/imagenet/human_readable_labels.json') as f:\n",
    "    label_strings = np.array(json.load(f))\n",
    "\n",
    "example_paths =os.listdir('../data/imagenet/examples')\n",
    "for i in range(10):\n",
    "    rand_path = np.random.choice(example_paths)\n",
    "    img = imread('../data/imagenet/examples/' + rand_path )\n",
    "    img_index = int(rand_path.split('.')[0])\n",
    "    # Form the prediction set\n",
    "\n",
    "    \n",
    "    _smx = smx[img_index]         #TODO OPERAND\n",
    "    _pi = np.argsort(_smx)[::-1]  #TODO OPERAND\n",
    "    _srt = np.take_along_axis(_smx,_pi,axis=0) #TODO OPERAND\n",
    "    _srt_cumsum = _srt.cumsum()        #TODO OPERAND\n",
    "    _ind = _srt_cumsum <= qhat  #TODO OPERAND\n",
    "    \n",
    "#     _smx = smx[img_index]         #TODO OPERAND\n",
    "#     _pi = np.argsort(_smx)[::-1]  #TODO OPERAND\n",
    "#     _srt = np.take_along_axis(_smx,_pi,axis=0) #TODO OPERAND\n",
    "#     _srt_reg_cumsum = _srt_reg.cumsum()        #TODO OPERAND\n",
    "#     _ind = (_srt_reg_cumsum - np.random.rand()*_srt_reg) <= qhat if rand else _srt_reg_cumsum - _srt_reg <= qhat #TODO OPERAND\n",
    "\n",
    "    if disallow_zero_sets: _ind[0] = True\n",
    "    prediction_set = np.take_along_axis(_ind,_pi.argsort(),axis=0)\n",
    "    plt.figure()\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    send(plt, 24)\n",
    "    plt.show()\n",
    "    print(f\"The prediction set is: {list(label_strings[prediction_set])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another way for adaptive predictive sets in classification\n",
    "\n",
    "\n",
    "[Sadinle, Lei, Wasserman] https://arxiv.org/abs/1609.00451\n",
    "\n",
    "\n",
    "[Notebook source](https://github.com/aangelopoulos/conformal-prediction/blob/main/notebooks/imagenet-raps.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set RAPS regularization parameters (larger lam_reg and smaller k_reg leads to smaller sets)\n",
    "lam_reg = 0.01\n",
    "k_reg = 5\n",
    "disallow_zero_sets = False # Set this to False in order to see the coverage upper bound hold\n",
    "rand = True # Set this to True in order to see the coverage upper bound hold\n",
    "reg_vec = np.array(k_reg*[0,] + (smx.shape[1]-k_reg)*[lam_reg,])[None,:] # create a row with 5 zeroes and the rest at 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get scores\n",
    "\n",
    "# get for each row the position of the predicted probabilities in decreasing order\n",
    "cal_pi = cal_smx.argsort(1)[:,::-1] #argsort in increasing order, so order reverting by [:,::-1] \n",
    "\n",
    "# form for each row the predicted probabilities in decreasing order\n",
    "cal_srt = np.take_along_axis(cal_smx,cal_pi,axis=1)\n",
    "\n",
    "cal_srt_reg = cal_srt + reg_vec # addition row by row of 0 0 0 0 0 0.1 0.1 ....\n",
    "\n",
    "# get the rank of the true label in the sorted predicted probabilities\n",
    "cal_L = np.where(cal_pi == cal_labels[:,None])[1]\n",
    "\n",
    "# compute the calibration scores (why minus something????)\n",
    "cal_scores = cal_srt_reg.cumsum(axis=1)[np.arange(n_cal),cal_L] - np.random.rand(n_cal)*cal_srt_reg[np.arange(n_cal),cal_L]\n",
    "\n",
    "# Get the score quantile\n",
    "qhat = np.quantile(cal_scores, np.ceil((n_cal+1)*(1-alpha))/n_cal, interpolation='higher')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Deploy\n",
    "n_test = test_smx.shape[0]\n",
    "test_pi = test_smx.argsort(1)[:,::-1] # sorting the predicted probabilities (softmax outputs) on the test set\n",
    "test_srt = np.take_along_axis(test_smx,test_pi,axis=1) # reordering\n",
    "test_srt_reg = test_srt + reg_vec # ???\n",
    "test_srt_reg_cumsum = test_srt_reg.cumsum(axis=1) # cumulative softmax outputs\n",
    "indicators = (test_srt_reg.cumsum(axis=1) - np.random.rand(n_test,1)*test_srt_reg) <= qhat if rand else test_srt_reg.cumsum(axis=1) - test_srt_reg <= qhat\n",
    "if disallow_zero_sets: indicators[:,0] = True\n",
    "prediction_sets = np.take_along_axis(indicators,test_pi.argsort(axis=1),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate empirical coverage\n",
    "empirical_coverage = prediction_sets[np.arange(n_test),test_labels].mean()\n",
    "print(f\"The empirical coverage is: {empirical_coverage}\")\n",
    "print(f\"The quantile is: {qhat}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Show some examples\n",
    "with open('../data/imagenet/human_readable_labels.json') as f:\n",
    "    label_strings = np.array(json.load(f))\n",
    "\n",
    "example_paths =os.listdir('../data/imagenet/examples')\n",
    "for i in range(10):\n",
    "    rand_path = np.random.choice(example_paths)\n",
    "    img = imread('../data/imagenet/examples/' + rand_path )\n",
    "    img_index = int(rand_path.split('.')[0])\n",
    "    # Form the prediction set\n",
    "    _smx = smx[img_index]\n",
    "    _pi = np.argsort(_smx)[::-1]\n",
    "    _srt = np.take_along_axis(_smx,_pi,axis=0)\n",
    "    _srt_reg = _srt + reg_vec.squeeze()\n",
    "    _srt_reg_cumsum = _srt_reg.cumsum()\n",
    "    _ind = (_srt_reg_cumsum - np.random.rand()*_srt_reg) <= qhat if rand else _srt_reg_cumsum - _srt_reg <= qhat\n",
    "    if disallow_zero_sets: _ind[0] = True\n",
    "    prediction_set = np.take_along_axis(_ind,_pi.argsort(),axis=0)\n",
    "    plt.figure()\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    print(f\"The prediction set is: {list(label_strings[prediction_set])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
